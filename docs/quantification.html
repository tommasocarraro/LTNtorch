<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quantification in Logic Tensor Networks &mdash; LTNtorch 0.9 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Stable Fuzzy Semantics" href="stableconf.html" />
    <link rel="prev" title="LTN broadcasting" href="broadcasting.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> LTNtorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="grounding.html">Grounding in Logic Tensor Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="learningltn.html">Introduction to Learning in Logic Tensor Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="ltnobjects.html">LTN objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="broadcasting.html">LTN broadcasting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-predicate-case">LTN predicate case</a></li>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-function-case">LTN function case</a></li>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-connective-case">LTN connective case</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quantification in Logic Tensor Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#base-quantification">Base quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#diagonal-quantification">Diagonal quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#guarded-quantification">Guarded quantification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stableconf.html">Stable Fuzzy Semantics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="core.html">ltn.core</a><ul>
<li class="toctree-l2"><a class="reference internal" href="core.html#members">Members</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="fuzzy_ops.html">ltn.fuzzy_ops</a><ul>
<li class="toctree-l2"><a class="reference internal" href="fuzzy_ops.html#members">Members</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">LTNtorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Quantification in Logic Tensor Networks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quantification.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quantification-in-logic-tensor-networks">
<h1>Quantification in Logic Tensor Networks<a class="headerlink" href="#quantification-in-logic-tensor-networks" title="Permalink to this headline"></a></h1>
<section id="base-quantification">
<span id="quantification"></span><h2>Base quantification<a class="headerlink" href="#base-quantification" title="Permalink to this headline"></a></h2>
<p>The logical quantifiers, namely <span class="math notranslate nohighlight">\(\forall\)</span> and <span class="math notranslate nohighlight">\(\exists\)</span>, are implemented in LTN using fuzzy aggregators. An
example of fuzzy aggregator is the mean. The <a class="reference internal" href="fuzzy_ops.html#module-ltn.fuzzy_ops" title="ltn.fuzzy_ops"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops</span></code></a> module contains the implementation
of the most common fuzzy aggregators.</p>
<p>In the note regarding the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, we have seen that the output of logical predicates, for
example <span class="math notranslate nohighlight">\(P(x, y)\)</span>, is organized in a tensor where the dimensions are related with the free variables appearing in the
predicate. In the case of the atomic formula <span class="math notranslate nohighlight">\(P(x, y)\)</span>, the result is a tensor <span class="math notranslate nohighlight">\(\mathbf{out} \in [0., 1.]^{m \times n}\)</span>,
where <span class="math notranslate nohighlight">\(m\)</span> is the number of individuals of variable <span class="math notranslate nohighlight">\(x\)</span>, while <span class="math notranslate nohighlight">\(n\)</span> is the number of individuals of variable <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Notice that:</p>
<ol class="arabic simple">
<li><p>the tensor <span class="math notranslate nohighlight">\(\mathbf{out}\)</span> has two dimensions because the atomic formula <span class="math notranslate nohighlight">\(P(x, y)\)</span> has two free variables, namely <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>;</p></li>
<li><p>variable <span class="math notranslate nohighlight">\(x\)</span> has been placed on the first dimension, while variable <span class="math notranslate nohighlight">\(y\)</span> in the second dimension, according to their order of appearance in the atomic formula;</p></li>
<li><p>the output of the predicate is wrapped inside an <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> where the <cite>value</cite> attribute contains the tensor <span class="math notranslate nohighlight">\(\mathbf{out}\)</span>, while the <cite>free_vars</cite> attribute contains the list <cite>[‘x’, ‘y’]</cite>.</p></li>
</ol>
<p>Now, we can extend this example with the formula: <span class="math notranslate nohighlight">\(\forall x P(x, y)\)</span>. In order to compute the result of this formula,
LTNtorch must compute the result of the atomic formula <span class="math notranslate nohighlight">\(P(x, y)\)</span> first, and then apply a fuzzy aggregator to this
result for performing the desired quantification on variable <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>We know that the output of <span class="math notranslate nohighlight">\(P(x, y)\)</span> is the tensor <span class="math notranslate nohighlight">\(\mathbf{out} \in [0., 1.]^{m \times n}\)</span>, and that the
first dimension is related to variable <span class="math notranslate nohighlight">\(x\)</span> while second dimension to variable <span class="math notranslate nohighlight">\(y\)</span>. In order to perform the
quantification of <span class="math notranslate nohighlight">\(P(x, y)\)</span> on variable <span class="math notranslate nohighlight">\(x\)</span>, LTNtorch simply performs an aggregation of tensor
<span class="math notranslate nohighlight">\(\mathbf{out}\)</span> on the first dimension. Let us assume that the selected fuzzy aggregator for <span class="math notranslate nohighlight">\(\forall\)</span> is the mean.
LTNtorch simply computes <cite>torch.mean(out, dim=0)</cite>, where <cite>out</cite> is the tensor <span class="math notranslate nohighlight">\(\mathbf{out}\)</span> and <cite>dim=0</cite> means that
we aggregate on the first dimension of <cite>out</cite>, namely the dimension related to variable <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>After the application of the quantifier, a new <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> is created. The attribute <cite>value</cite> will contain
the result of <span class="math notranslate nohighlight">\(\forall x P(x, y)\)</span>, that will be the tensor <span class="math notranslate nohighlight">\(\mathbf{out}' \in [0., 1.]^n\)</span>, while the attribute
<cite>free_vars</cite> will contain the list <cite>[‘y’]</cite>.</p>
<p>Notice that:</p>
<ol class="arabic simple">
<li><p>the result has one less dimension within respect to the result of <span class="math notranslate nohighlight">\(P(x, y)\)</span>. This is due to the fact that we have aggregated one of the two dimensions, namely the dimension of <span class="math notranslate nohighlight">\(x\)</span>. The only dimension left is the dimension related with <span class="math notranslate nohighlight">\(y\)</span>, and it is for this reason that <span class="math notranslate nohighlight">\(\mathbf{out}\)</span> is now a vector in <span class="math notranslate nohighlight">\([0., 1.]^n\)</span>;</p></li>
<li><p>the attribute <cite>free_vars</cite> contains now only variable <span class="math notranslate nohighlight">\(y\)</span>. This is due to the fact that variable <span class="math notranslate nohighlight">\(x\)</span> is not free anymore since it has been quantified by <span class="math notranslate nohighlight">\(\forall\)</span>.</p></li>
</ol>
<p>Finally, notice that if the formula would have been <span class="math notranslate nohighlight">\(\forall x \forall y P(x, y)\)</span>, the quantification would have been
<cite>torch.mean(out, dim=(0,1))</cite>, namely both dimensions of <span class="math notranslate nohighlight">\(\mathbf{out}\)</span> would have been aggregated. Also, the output
would have been a scalar in <span class="math notranslate nohighlight">\([0., 1.]\)</span> and no more free variables would have been in the formula, since both variables
have been quantified.</p>
</section>
<section id="diagonal-quantification">
<h2>Diagonal quantification<a class="headerlink" href="#diagonal-quantification" title="Permalink to this headline"></a></h2>
<p id="diagonal">Given 2 (or more) variables, there are scenarios where one wants to express statements about specific pairs (or tuples)
of values only, instead of all the possible combinations of values of the variables. This is allowed in LTN thanks to the concept
of diagonal quantification.</p>
<p>To make the concept clear, let us make a simple example. Suppose that we have the formula <span class="math notranslate nohighlight">\(\forall x \forall y P(x, y)\)</span>.
Suppose also that variables <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> have the same number of individuals, and that this number is <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>With the usual <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, the predicate <span class="math notranslate nohighlight">\(P(x, y)\)</span> is computed on all the possible
combinations of individuals of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. In other words, the result of <span class="math notranslate nohighlight">\(P(x, y)\)</span> would be a tensor
<span class="math notranslate nohighlight">\(\mathbf{out} \in [0., 1.]^{n \times n}\)</span>. Then, after the quantification on both <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, we obtain
a scalar in <span class="math notranslate nohighlight">\([0., 1.]\)</span>.</p>
<p>With diagonal quantification (<span class="math notranslate nohighlight">\(\forall Diag(x, y) P(x, y)\)</span>), instead, predicate <span class="math notranslate nohighlight">\(P(x, y)\)</span> is computed only on the tuples <span class="math notranslate nohighlight">\((x_i, y_i)\)</span>, where
<span class="math notranslate nohighlight">\(x_i\)</span> is the <span class="math notranslate nohighlight">\(i_{th}\)</span> individual of <span class="math notranslate nohighlight">\(x\)</span>, while <span class="math notranslate nohighlight">\(y_i\)</span> is the <span class="math notranslate nohighlight">\(i_{th}\)</span> individual of <span class="math notranslate nohighlight">\(y\)</span>.
In other words, the output would be a tensor <span class="math notranslate nohighlight">\(\mathbf{out} \in [0., 1.]^n\)</span>. Notice that the output has one single dimension
since the predicate has been computed on <span class="math notranslate nohighlight">\(n\)</span> tuples only, namely the tuples created constructing a one-to-one correspondence
between the individuals of <span class="math notranslate nohighlight">\(x\)</span> and the individuals <span class="math notranslate nohighlight">\(y\)</span>. At the end, after the quantification, a scalar is obtained like in the
case with the previous case.</p>
<p>The advantages of diagonal quantification are mani-fold:</p>
<ol class="arabic simple">
<li><p>it is a way to disable the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>. Even if it has been designed to work with quantified statements, it could serve as a way to temporarily disable the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> when computing some formulas. In fact, sometimes it is not necessary to compute a predicate on all the possible combinations of individuals of the variables in input;</p></li>
<li><p>it is more efficient compared to the usual quantification since it allows to avoid to compute a predicate on all the possible combinations of individuals of the variables appearing in the predicate;</p></li>
<li><p>it is useful when dealing with variables which represent machine learning examples. In many tasks, the dataset comes with some labelled examples. One variable could contain the examples, while another variable could contain the labels of the examples. With diagonal quantification we are able to force LTNtorch to use these variables with a one-to-one correspondence. This allows to avoid to compute formulas on combination of individuals which do not make any sense, for example a data sample labelled with a wrong label.</p></li>
</ol>
<p>Notice that diagonal quantification expects the variables to have the same number of individuals, since a one-to-one correspondence has to be created.</p>
<p>In order to use diagonal quantification in LTNtorch, it is possible to use <a class="reference internal" href="core.html#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a>.</p>
</section>
<section id="guarded-quantification">
<h2>Guarded quantification<a class="headerlink" href="#guarded-quantification" title="Permalink to this headline"></a></h2>
<p id="guarded">In some cases, it could be useful to quantify formulas only on variables’ individuals which satisfy a given condition.
This is allowed in LTN by using the guarded quantification.</p>
<p>To make the concept clear, let us make a simple example. Suppose that we have a binary predicate <span class="math notranslate nohighlight">\(P(a, b)\)</span>. Then, we have two variables,
<span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, containing sequences of points in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>. Specifically,
<span class="math notranslate nohighlight">\(\mathcal{G}(x) \in \mathbb{R}^{m_1 \times 2}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{G}(y) \in \mathbb{R}^{m_2 \times 2}\)</span>. So, <span class="math notranslate nohighlight">\(x\)</span> contains
<span class="math notranslate nohighlight">\(m_1\)</span> points, while <span class="math notranslate nohighlight">\(m_2\)</span> contains <span class="math notranslate nohighlight">\(m_2\)</span> points.</p>
<p>We have already seen that LTN allows to compute the formula: <span class="math notranslate nohighlight">\(\forall x \forall y P(x, y)\)</span>. Also,
we know that LTNtorch firstly computes <span class="math notranslate nohighlight">\(P(x, y)\)</span> and then aggregates on the dimensions specified by the quantified variables.</p>
<p>Suppose now that we want to compute the same formula <span class="math notranslate nohighlight">\(\forall x \forall y P(x, y)\)</span> but quantifying only on the pairs of
points whose distance is lower than a certain threshold. We represent this threshold with the constant <span class="math notranslate nohighlight">\(th\)</span>. In Real Logic,
it is possible to formalize this statement as <span class="math notranslate nohighlight">\(\forall x \forall y : (dist(x, y) &lt; th) \text{ } P(x, y)\)</span>, where <span class="math notranslate nohighlight">\(dist\)</span> is
a function which computes the Euclidean distance between two points in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>.</p>
<p>In order to compute this formula, LTNtorch follows this procedure:</p>
<ol class="arabic simple">
<li><p>it computes the result of the atomic formula <span class="math notranslate nohighlight">\(P(x, y)\)</span>, which is a tensor <span class="math notranslate nohighlight">\(\mathbf{out} \in [0., 1.]^{m_1 \times m_2}\)</span>;</p></li>
<li><p>it masks the truth values in the tensor <span class="math notranslate nohighlight">\(\mathbf{out}\)</span> which do not satisfy the given condition (<span class="math notranslate nohighlight">\(dist(x, y) &lt; th\)</span>);</p></li>
<li><p>it aggregates the tensor <span class="math notranslate nohighlight">\(mathbf{out}\)</span> on both dimensions, since both variables have been quantified. In this aggregation, the truth values masked by the previous step are not considered. Since both variables have been quantified, the result is a scalar in <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p></li>
</ol>
<p>For applying guarded quantification in LTNtorch, see <a class="reference internal" href="core.html#ltn.core.Quantifier" title="ltn.core.Quantifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Quantifier</span></code></a>. In particular, see <cite>mask_fn</cite>
and <cite>cond_vars</cite> parameters.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="broadcasting.html" class="btn btn-neutral float-left" title="LTN broadcasting" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="stableconf.html" class="btn btn-neutral float-right" title="Stable Fuzzy Semantics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Tommaso Carraro.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>