{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Grounding in LTN (continuation)\n",
    "\n",
    "This tutorial explains how to ground connectives and quantifiers in LTN. It expects some familiarity with the first tutorial on grounding non-logical symbols (constants, variables, functions and predicates)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import ltn\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connectives\n",
    "\n",
    "LTN supports various logical connectives. They are grounded using fuzzy semantics. The implementation of some of the most\n",
    "common fuzzy semantics using PyTorch primitives is included in the `ltn.fuzzy_ops` module.\n",
    "\n",
    "In general, we recommend using the following semantics for LTN connectives:\n",
    "* the standard negation  $\\lnot u = 1-u$;\n",
    "* the product t-norm $u \\land v = uv$;\n",
    "* the product t-conorm (probabilistic sum) $u \\lor v = u+v-uv$;\n",
    "* the Reichenbach implication $u \\rightarrow v = 1 - u + uv$;\n",
    "\n",
    "where $u$ and $v$ denote two truth values in $[0,1]$.\n",
    "\n",
    "For more details about the choice of the right fuzzy semantics for your task, we suggest reading the complementary notebook (2b-grounding_connectives.ipynb).\n",
    "\n",
    "In LTN, creating a connective is really simple. It is possible to use the constructor `Connective()`, which takes as input a\n",
    "unary or binary fuzzy connective semantics. It is possible to choice the semantics from the `ltn.fuzzy_ops` module.\n",
    "\n",
    "In this tutorial, we use the connective fuzzy semantics suggested above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In particular, the wrapper `ltn.Connective` allows to use the operators with LTN formulas. Specifically, it takes care\n",
    "of combining sub-formulas which have different variables appearing in them (the sub-formulas may have different dimensions\n",
    "that need to be \"broadcasted\" in order to apply the connective).\n",
    "\n",
    "In this example, we create two variables with different number of individuals, two constants, and a predicate measuring the similarity between two points in $\\mathbb{R}^2$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0178)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ltn.Variable('x', torch.randn((10, 2))) # 10 values in R²\n",
    "y = ltn.Variable('y', torch.randn((5, 2))) # 5 values in R²\n",
    "\n",
    "c1 = ltn.Constant(torch.tensor([0.5, 0.0]))\n",
    "c2 = ltn.Constant(torch.tensor([4.0, 2.0]))\n",
    "\n",
    "Eq = ltn.Predicate(func=lambda x, y: torch.exp(-torch.norm(x - y, dim=1))) # predicate measuring similarity\n",
    "\n",
    "Eq(c1, c2).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we check the behavior of the logical connectives. It is easy to see that they behave according to the definition\n",
    "written at the beginning of the tutorial.\n",
    "\n",
    "Notice the shape printed in the last two lines of code. In the first one, since only variable x appears in the formula,\n",
    "we have a shape of 5. The formula has been evaluated for each x.\n",
    "In the second one, since both x and y appear in the formula, we have a shape of 10x5.\n",
    "The formula has been evaluated for each combination of x and y."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9822)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Not(Eq(c1, c2)).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9825)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Implies(Eq(c1, c2), Eq(c2, c1)).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the dimension of the outcome: the result is evaluated for every x.\n",
    "And(Eq(x, c1), Eq(x, c2)).shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 5])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the dimensions of the outcome: the result is evaluated for every x and y.\n",
    "# Notice also that y did not appear in the 1st argument of `Or`;\n",
    "# the connective broadcasts the results of its two arguments to match.\n",
    "Or(Eq(x, c1), Eq(x, y)).shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the access to the `value` attribute or `shape()` method of the evaluation of the connective. This is done because LTN connectives return `LTNObject` instances, like it happens for predicates and functions.\n",
    "\n",
    "## Quantifiers\n",
    "\n",
    "LTN suppports universal and existential quantification. They are grounded using aggregation operators. We recommend using the following two operators:\n",
    "\n",
    "- existential quantification (\"exists\"):\n",
    "the generalized mean (`pMean`) $\\mathrm{pM}(u_1,\\dots,u_n) = \\biggl( \\frac{1}{n} \\sum\\limits_{i=1}^n u_i^p \\biggr)^{\\frac{1}{p}} \\qquad p \\geq 1$;\n",
    "- universal quantification (\"for all\"):\n",
    "the generalized mean of \"the deviations w.r.t. the truth\" (`pMeanError`) $\\mathrm{pME}(u_1,\\dots,u_n) = 1 - \\biggl( \\frac{1}{n} \\sum\\limits_{i=1}^n (1-u_i)^p \\biggr)^{\\frac{1}{p}} \\qquad p \\geq 1$;\n",
    "\n",
    "where $u_1,\\dots,u_n$ is a list of truth values in $[0,1]$.\n",
    "\n",
    "In LTN, creating a quantifier is really simple. It is possible to use the constructor `Quantifier()`, which takes as input\n",
    "an aggregation semantics and a character indicating which type of quantification is associated to the quantifier (\"e\" for exists, \"f\" for forall).\n",
    "\n",
    "In this example, we create the quantifiers using the fuzzy semantics proposed above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The wrapper `ltn.Quantifier` allows to use the aggregators with LTN formulas. It takes care of selecting the tensor (formula)\n",
    "dimensions to aggregate, given some variables in arguments.\n",
    "\n",
    "In this example, we create variables and predicate similar to the previous example on connectives."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 5])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ltn.Variable('x', torch.randn((10, 2))) # 10 values in R²\n",
    "y = ltn.Variable('y', torch.randn((5, 2))) # 5 values in R²\n",
    "\n",
    "Eq = ltn.Predicate(func=lambda x, y: torch.exp(-torch.norm(x - y, dim=1))) # predicate measuring similarity\n",
    "\n",
    "Eq(x, y).shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we apply some quantifiers to the formula, and we see how this effects the output and its shape.\n",
    "\n",
    "In the first case, we have quantified on x, so the output has shape 5. This means we have removed the dimension related to x and only dimension related to y is left. The shape is 5 since y has 5 individuals.\n",
    "\n",
    "In the other three cases, the output is a scalar since the quantification has been performed on both variables. This means the aggregation has been performed on both dimension, namely the dimension of x and the dimension of y."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall(x, Eq(x, y)).shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3004)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall([x, y], Eq(x, y)).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4113)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exists([x, y], Eq(x, y)).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3635)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall(x, Exists(y, Eq(x, y))).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice the access to the `value` attribute or `shape()` method of the evaluation of the quantifier. This is done because LTN quantifiers return `LTNObject` instances, like it happens for predicates, functions, and connectives.\n",
    "\n",
    "It is important to observe that when the quantification is performed on a single variable, it is possible to give the variable\n",
    "to the quantifier as it comes, instead, if the quantification has to be performed on more variables, it is required to give the variables to the quantifier\n",
    "through a list, as it happens for the second and third example.\n",
    "\n",
    "## Semantics for quantifiers\n",
    "\n",
    "`pMean` semantics can be understood as a soft-maximum that depends on the hyper-paramer $p$:\n",
    "- $p \\to 1$: the operator tends to `mean`,\n",
    "- $p \\to +\\infty$: the operator tends to `max`.\n",
    "\n",
    "Similarly, `pMeanError` semantics can be understood as a soft-minimum:\n",
    "- $p \\to 1$: the operator tends to `mean`,\n",
    "- $p \\to +\\infty$: the operator tends to `min`.\n",
    "\n",
    "Intuitively, $p$ offers flexibility in writing more or less strict formulas, to account for outliers in the data depending on the application.\n",
    "\n",
    "Note that different choices of $p$ could have strong implications during the training (see 2b-grounding_connectives.ipynb).\n",
    "\n",
    "One can set a default value for $p$ when initializing the operator, or can use different values at each call of the operator.\n",
    "\n",
    "In this example, we use the quantifiers with different values of the $p$ parameter.\n",
    "\n",
    "In general, higher is $p$ and easier is the existential quantification to be satisfied, while harder is the universal quantification to be satisfied."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4100)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall(x, Eq(x, c1), p=2).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2308)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forall(x, Eq(x, c1), p=10).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4980)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exists(x, Eq(x, c1), p=2).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.6306)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exists(x, Eq(x, c1), p=10).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Diagonal Quantification\n",
    "\n",
    "Given 2 (or more) variables, there are scenarios where one wants to express statements about specific pairs (or tuples) only, such that the $i$-th tuple contains the $i$-th instances of the variables.\n",
    "In other words, in some cases we do not want to evaluate a formula on all the possible combination of individuals of the variables involved in it.\n",
    "\n",
    "We allow this using `ltn.diag` (diagonal quantification).\n",
    "\n",
    "**Note**: diagonal quantification assumes that the variables have the same number of individuals.\n",
    "This is intuitive since we need a one-to-one correspondence between the individuals of the variables involved in the quantification.\n",
    "\n",
    "In simplified pseudo-code, the usual quantification would compute:\n",
    "```python\n",
    "for x_i in x:\n",
    "    for y_j in y:\n",
    "        results.append(P(x_i,y_j))\n",
    "aggregate(results)\n",
    "```\n",
    "In contrast, diagonal quantification would compute:\n",
    "```python\n",
    "for x_i, y_i in zip(x,y):\n",
    "    results.append(P(x_i,y_i))\n",
    "aggregate(results)\n",
    "```\n",
    "\n",
    "We illustrate `ltn.diag` in the following setting:\n",
    "- the variable $x$ denotes 100 individuals in $\\mathbb{R}^{2\\times2}$,\n",
    "- the variable $l$ denotes 100 one-hot labels in $\\mathbb{N}^3$ (3 possible classes),\n",
    "- $l$ is grounded according to $x$ such that each pair $(x_i,l_i)$, for $i=0..100$ denotes one correct example from the dataset,\n",
    "- the classifier $C(x,l)$ gives a confidence value in $[0,1]$ of the sample $x$ corresponding to the label $l$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# The values are generated at random, for the sake of illustration.\n",
    "# In a real scenario, they would come from a dataset.\n",
    "samples = torch.randn((100, 2, 2)) # 100 R^{2x2} values\n",
    "labels = torch.randint(0, 3, size=(100,)) # 100 labels (class 0/1/2) that correspond to each sample\n",
    "onehot_labels = torch.nn.functional.one_hot(labels, num_classes=3)\n",
    "\n",
    "x = ltn.Variable(\"x\", samples)\n",
    "l = ltn.Variable(\"l\", onehot_labels)\n",
    "\n",
    "class ModelC(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelC, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.dense1 = torch.nn.Linear(4, 5)\n",
    "        self.dense2 = torch.nn.Linear(5, 3)\n",
    "\n",
    "    def forward(self, x, l):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.elu(self.dense1(x))\n",
    "        x = self.softmax(self.dense2(x))\n",
    "        return torch.sum(x * l, dim=1)\n",
    "\n",
    "C = ltn.Predicate(ModelC())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If some variables are marked using `ltn.diag`, LTN will only compute their \"zipped\" results (instead of the usual \"broadcasting\").\n",
    "\n",
    "In other words, the formula will be evaluated only on specific tuples of individuals instead of being evaluated on all the possible combinations of individuals of the variables.\n",
    "\n",
    "It is possible to observe that the shape of the first evaluation is 100x100. This happens because LTN generates all the possible\n",
    "combinations of individuals of $x$ and $l$, and then applies the predicate.\n",
    "\n",
    "Note how the shape changes after applying `ltn.diag`. This happens because the individuals of the two variables are taken in one-to-one correspondence and the predicate\n",
    "is computed only on that specific tuples of individuals.\n",
    "\n",
    "Notice how the `free_vars` attribute of the variables is changed after a diagonal setting has been set. It is possible to recognize\n",
    "if a variable is in diagonal setting by checking if its label begins with \"diag_\". In particular, all the variables in the same\n",
    "diagonal setting will share the same label.\n",
    "\n",
    "It is possible to use `ltn.undiag` to obtain the opposite behavior. In other words, it removes the diagonal setting from the variables\n",
    "and restore the usual LTN broadcasting for the variables. This is clarified from the last print."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "['diag_x_l']\n",
      "['diag_x_l']\n",
      "torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "print(C(x, l).shape()) # Computes the 100x100 combinations\n",
    "ltn.diag(x, l) # sets the diag behavior for x and l\n",
    "print(C(x, l).shape())# Computes the 100 zipped combinations\n",
    "print(x.free_vars)\n",
    "print(l.free_vars)\n",
    "ltn.undiag(x, l) # resets the normal behavior\n",
    "print(C(x, l).shape()) # Computes the 100x100 combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In practice, `ltn.diag` is designed to be used with quantifiers.\n",
    "Every quantifier automatically calls `ltn.undiag` after the aggregation is performed, so that the variables keep their normal\n",
    "behavior outside of the formula.\n",
    "Therefore, it is recommended to use `ltn.diag` only in quantified formulas as follows.\n",
    "\n",
    "Notice the call to `ltn.undiag` by the quantifier. After the quantification has been performed, the two variables restore their original labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diag_x_l']\n",
      "['diag_x_l']\n",
      "tensor(0.3382, grad_fn=<RsubBackward1>)\n",
      "['x']\n",
      "['l']\n"
     ]
    }
   ],
   "source": [
    "x, l = ltn.diag(x, l)\n",
    "print(x.free_vars)\n",
    "print(l.free_vars)\n",
    "print(Forall([x, l], C(x, l)).value) # Aggregates only on the 100 \"zipped\" pairs.\n",
    "                                    # Automatically calls `ltn.undiag` so the behavior of x/l is unchanged outside of this formula.\n",
    "print(x.free_vars)\n",
    "print(l.free_vars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Guarded Quantifiers\n",
    "\n",
    "One may wish to quantify over a set of elements whose grounding satisfy some **boolean** condition.\n",
    "\n",
    "Let us assume $x$ is a variable from some domain and $m$ is a mask function that returns boolean values (that is, $0$ or $1$, not continuous truth degrees in $[0,1]$) for each element of the domain.\n",
    "\n",
    "In guarded quantification, one has quantifications of the form:\n",
    "\n",
    "- $(\\forall x: m(x)) \\text{ } \\phi(x)$\n",
    "which means \"every x satisfying $m(x)$ also satisfies $\\phi(x)$\";\n",
    "- $(\\exists x: m(x)) \\text{ } \\phi(x)$\n",
    "which means \"some x satisfying $m(x)$ also satisfies $\\phi(x)$\".\n",
    "\n",
    "The mask $m$ can also depend on other variables in the formula. For instance, the quantification $\\exists y (\\forall x:m(x,y)) \\text{ } \\phi(x,y)$ is also a valid sentence.\n",
    "\n",
    "Let us consider the following example, that states that there exists an euclidian distance $d$ below which all pairs of points $x$, $y$ should be considered as similar:\n",
    "$\\exists d \\ (\\forall x,y : \\mathrm{dist}(x,y) < d) \\ ( \\mathrm{Eq}(x,y))) $.\n",
    "\n",
    "In this example, $Eq$ is a predicate measuring the similarity between two points, while $dist$ is a function which computes the euclidean distance between two points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "Eq = ltn.Predicate(func=lambda x, y: torch.exp(-torch.norm(x - y, dim=1))) # predicate measuring similarity\n",
    "\n",
    "points = torch.rand((50, 2)) # 50 values in [0,1]^2\n",
    "x = ltn.Variable(\"x\", points)\n",
    "y = ltn.Variable(\"y\", points)\n",
    "d = ltn.Variable(\"d\", torch.tensor([.1,.2,.3,.4,.5,.6,.7,.8,.9]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7583, dtype=torch.float64)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = lambda x, y: torch.unsqueeze(torch.norm(x.value - y.value, dim=1), 1) # function measuring euclidian distance\n",
    "Exists(d,\n",
    "      Forall([x, y],\n",
    "            Eq(x, y),\n",
    "            cond_vars=[x, y, d],\n",
    "            cond_fn=lambda x, y, d: dist(x, y) < d.value\n",
    "            )).value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As showed in the example, in order to use a guarded quantification it is enough to specify some condition variables (`cond_vars` parameter) and a\n",
    "condition function (`cond_fn` parameter). In particular, `cond_vars` requires a list of LTN variables, while\n",
    "`cond_fn` requires a function. The function computes a boolean mask, then the mask is used to select the values on which\n",
    "the aggregation has to be computed.\n",
    "\n",
    "In this specific example, the guarded quantification is used for aggregating over pairs of points whose distance is under a certain\n",
    "threshold, specified by variable $d$. All the other pairs of points are not considered during the aggregation.\n",
    "\n",
    "The guarded option is particularly useful to propagate gradients (see notebook on learning) only over a subset of the\n",
    "domains, namely the domains which verifies the condition $m$."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}