{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Learning embeddings with LTN\n",
    "\n",
    "A classic example of Statistical Relational Learning is the smokers-friends-cancer example introduced in the paper\n",
    "about Markov Logic Networks. Below, we show how this example can be formalized in LTN using semi-supervised\n",
    "embedding learning.\n",
    "\n",
    "The problem is the following. There are 14 people divided into two groups $\\{a, b, \\dots, h\\}$ and $\\{i, j, \\dots, n\\}$.\n",
    "Within each group, there is complete knowledge about smoking habits. In the first group, there is complete knowledge\n",
    "about who has and who does not have cancer. Knowledge about the friendship relation is complete within each group only\n",
    "if symmetry is assumed, that is, $\\forall x,y \\text{ } (friends(x,y) \\implies friends(y,x))$. Otherwise, knowledge about\n",
    "friendship is incomplete in that it may be known that e.g. $a$ is a friend of $b$, and it may be not known whether\n",
    "$b$ is a friend of $a$. Finally, there is general knowledge about smoking, friendship and cancer, namely that smoking\n",
    "causes cancer, friendship is normally symmetric and anti-reflexive, everyone has a friend, and smoking propagates\n",
    "(actively or passively) among friends. All this knowledge is represented in the axioms further below.\n",
    "\n",
    "For this specific task, LTN uses the following language and grounding:\n",
    "\n",
    "**Domains:**\n",
    "- $people$, denoting the individuals of the smokers-friends-cancer dataset.\n",
    "\n",
    "**Variables:**\n",
    "- $x, y$ ranging over the individuals;\n",
    "- $D(x) = D(y) = people$.\n",
    "\n",
    "**Constants:**\n",
    "- $a, b, \\dots, h, i, j, \\dots, n$, the 14 individuals. Our goal is to learn an adequate embedding for each constant;\n",
    "- $D(a) = D(b) = \\dots = D(n) = people$.\n",
    "\n",
    "**Predicates:**\n",
    "- $S(x)$ for *smokes*, $F(x,y)$ for *friends*, $C(x)$ for *cancer*;\n",
    "- $D_{in}(S) = D_{in}(C) = people$;\n",
    "- $D_{in}(F) = people,people$.\n",
    "\n",
    "**Axioms:**\n",
    "\n",
    "Let $\\mathcal{X}_1 = \\{a, b, \\dots, h\\}$ and $\\mathcal{X}_2 = \\{i, j, \\dots, n\\}$ be the two set of individuals.\n",
    "\n",
    "Let $\\mathcal{S} = \\{a, e, f, g, j, n\\}$ be the set of the smokers. Knowledge is complete in both groups.\n",
    "\n",
    "Let $\\mathcal{C} = \\{a, e\\}$ be the set of individuals with cancer. Knowledge is complete on $\\mathcal{X}_1$ only.\n",
    "\n",
    "Let $\\mathcal{F} = \\{(a,b), (a,e), (a, f), (a, g), (b, c), (c, d), (e, f), (g, h), (i, j), (j, m), (k, l), (m, n)\\}$ be the\n",
    "set of friendship relations. Knowledge is complete if assuming symmetry.\n",
    "\n",
    "These facts are illustrated in the following figure.\n",
    "\n",
    "![Facts](./images/facts.png)\n",
    "\n",
    "We have the following axioms:\n",
    "- $F(u,v)$ for $(u, v) \\in \\mathcal{F}$;\n",
    "- $\\lnot F(u, v)$ for $(u, v) \\notin \\mathcal{F}, u > v$;\n",
    "- $S(u)$ for $u \\in \\mathcal{S}$;\n",
    "- $\\lnot S(u)$ for $u \\in (\\mathcal{X}_1 \\cup \\mathcal{X}_2) \\backslash \\mathcal{S}$;\n",
    "- $C(u)$ for $u \\in \\mathcal{C}$;\n",
    "- $\\lnot C(u)$ for $u \\in \\mathcal{X}_1 \\backslash \\mathcal{C}$;\n",
    "- $\\forall x \\text{ } \\lnot F(x,x)$;\n",
    "- $\\forall x, y \\text{ } (F(x, y) \\implies F(y,x))$;\n",
    "- $\\forall x \\exists y \\text{ } F(x,y)$;\n",
    "- $\\forall x, y \\text{ } ((F(x, y) \\land S(x)) \\implies S(y))$;\n",
    "- $\\forall x \\text{ } (S(x) \\implies C(x))$;\n",
    "- $\\forall x \\text{ } (\\lnot C(x) \\implies \\lnot S(x))$.\n",
    "\n",
    "Notice that the knowledge base is not satisfiable in the strict logical sense of the word. For instance, $f$ is said to\n",
    "smoke but not to have cancer, which is inconsistent with the rule $\\forall x \\text{ } (S(x) \\implies C(x))$. Hence, it\n",
    "is important to adopt a probabilistic approach as done with MLN or a many-valued fuzzy logic interpretation as done\n",
    "with LTN. This allows to relax the constraints, leading to soft constraints. With soft constraints, it is possible to find\n",
    "a solution which maximally satisfy all the constraints and better generalizes real world data compared to hard constrains.\n",
    "\n",
    "**Grounding:**\n",
    "- $\\mathcal{G}(people)=\\mathbb{R}^{5}$. The model is expected to learn embeddings in $\\mathbb{R}^{5}$;\n",
    "- $\\mathcal{G}(a \\mid \\theta)=\\mathbf{v}_\\theta(a), \\dots \\mathcal{G}(n \\mid \\theta)=\\mathbf{v}_\\theta(n)$, where with\n",
    "$\\mathbf{v}_\\theta(x)$ we denote the vector containing the parameters of individual $x$, namely the embedding of $x$.\n",
    "Every individual is associated with a vector of 5 real numbers. The embedding is initialized randomly and uniformly;\n",
    "- $\\mathcal{G}(x \\mid \\theta)=\\mathcal{G}(y \\mid \\theta) = \\langle \\mathbf{v}_\\theta(a), \\dots, \\mathbf{v}_\\theta(n) \\rangle$, namely variables\n",
    "$x$ and $y$ are sequences of embeddings of the individuals in the dataset;\n",
    "- $\\mathcal{G}(S \\mid \\theta) : x \\mapsto \\sigma(\\operatorname{MLP\\_S}_\\theta(x))$, where $\\operatorname{MLP\\_S}_\\theta$\n",
    "has 1 output neuron. In other words, $S$ returns the probability that $x$ is a smoker, given its features (embedding) in\n",
    "input;\n",
    "- $\\mathcal{G}(F \\mid \\theta) : x,y \\mapsto \\sigma(\\operatorname{MLP\\_F}_\\theta(x,y))$, where $\\operatorname{MLP\\_F}_\\theta$\n",
    "has 1 output neuron. In other words, $F$ returns the probability that $x$ and $y$ are friends, given their features (embeddings) in\n",
    "input;\n",
    "- $\\mathcal{G}(C \\mid \\theta) : x \\mapsto \\sigma(\\operatorname{MLP\\_C}_\\theta(x))$, where $\\operatorname{MLP\\_C}_\\theta$\n",
    "has 1 output neuron. In other words, $C$ returns the probability that $x$ has cancer, given its features (embedding) in\n",
    "input.\n",
    "\n",
    "The *MLP* models for $S$, $F$, and $C$ are kept simple, so that most of the learning is focused on the embeddings.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Now, let's create our dataset, according to the specification defined above.\n",
    "\n",
    "In order to define the dataset, it is enough to create an embedding in $\\mathbb{R}^5$ for each individual. The individuals\n",
    "will be represented in LTN by learnable constants containing the embeddings of the individuals.\n",
    "\n",
    "Then, we have to define our knowledge, namely the two groups of people, who has cancer, who is a smoker, and the set of\n",
    "friendship relations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import ltn\n",
    "import torch\n",
    "\n",
    "embedding_size = 5\n",
    "\n",
    "# first group of people\n",
    "g1 = {person: ltn.Constant(torch.rand((embedding_size,)), trainable=True) for person in 'abcdefgh'}\n",
    "# second group of people\n",
    "g2 = {person: ltn.Constant(torch.rand((embedding_size,)), trainable=True) for person in 'ijklmn'}\n",
    "# group of all people\n",
    "g = {**g1, **g2}\n",
    "\n",
    "# we define friendship relations, who has cancer and who is a smoker\n",
    "friends = [('a', 'b'), ('a', 'e'), ('a', 'f'), ('a', 'g'), ('b', 'c'), ('c', 'd'), ('e', 'f'), ('g', 'h'),\n",
    "               ('i', 'j'), ('j', 'm'), ('k', 'l'), ('m', 'n')]\n",
    "smokes = ['a', 'e', 'f', 'g', 'j', 'n']\n",
    "cancer = ['a', 'e']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LTN setting\n",
    "\n",
    "In order to define our knowledge base (axioms), we need to define predicates $F,C,S$,\n",
    "connectives, quantifiers, and the `SatAgg` operator.\n",
    "\n",
    "For the connectives and quantifiers, we use the stable product configuration (seen in the tutorials).\n",
    "\n",
    "For predicates $F,C,S$, we use simple $MLP$ models with two hidden layers each.\n",
    "\n",
    "`SatAgg` is defined using the `pMeanError` aggregator."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# we define predicates F, C, and S\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP model used for defining the predicates of our problem.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes=(10, 16, 16, 1)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        \"\"\"\n",
    "        Given an individual x, the forward phase of this MLP returns the probability that the individual x is a smoker,\n",
    "        or has cancer, or is friend of y (if given and predicate is F).\n",
    "\n",
    "        :param x: individuals for which we have to compute the probability\n",
    "        :return: the probability that individual x is a smoker, or has cancer, or is friend of y (if given)\n",
    "        \"\"\"\n",
    "        x = list(x)\n",
    "        if len(x) == 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = torch.cat(x, dim=1)\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "        out = self.sigmoid(self.linear_layers[-1](x))\n",
    "        return out\n",
    "\n",
    "C = ltn.Predicate(MLP(layer_sizes=(5, 16, 16, 1)))\n",
    "S = ltn.Predicate(MLP(layer_sizes=(5, 16, 16, 1)))\n",
    "F = ltn.Predicate(MLP(layer_sizes=(10, 16, 16, 1)))\n",
    "\n",
    "# we define connectives, quantifiers, and SatAgg\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning\n",
    "\n",
    "Let us define $D$ the data set of all examples. The objective function with $\\mathcal{K}$\n",
    "is given by $\\operatorname{SatAgg}_{\\phi \\in \\mathcal{K}} \\mathcal{G}_{\\boldsymbol{\\theta}, x \\leftarrow \\boldsymbol{D}}(\\phi)$.\n",
    "\n",
    "In practice, the optimizer uses the following loss function:\n",
    "\n",
    "$\\boldsymbol{L}=\\left(1-\\underset{\\phi \\in \\mathcal{K}}{\\operatorname{SatAgg}} \\mathcal{G}_{\\boldsymbol{\\theta}, x \\leftarrow \\boldsymbol{B}}(\\phi)\\right)$\n",
    "\n",
    "where $B$ is a mini batch sampled from $D$.\n",
    "\n",
    "In the following, we learn our LTN in the embedding learning task using the satisfaction of the knowledge base as\n",
    "an objective. In other words, we want to learn the parameters $\\theta$ (embeddings + MLPs of predicates) in such a way the\n",
    "axioms in the knowledge base are maximally satisfied.\n",
    "\n",
    "We train our model for 1000 epochs and use the `Adam` optimizer. In particular, for $\\forall$, we use\n",
    "`pMeanError` with $p=2$ for all the rules, except for rules in $\\{\\forall x \\text{ } \\lnot F(x,x), \\forall x,y \\text{ } (F(x,y) \\implies F(y,x)) \\}$, for which we use $p=6$.\n",
    "The intuition behind this choice of $p$ is that no outliers are to be accepted for the friendship relation since it is\n",
    "expected to be symmetric and anti-reflexive, instead, outliers are accepted for the other rules.\n",
    "\n",
    "For $\\exists$, we use `pMean` with $p=1$ during the first 200 epochs of training, and $p=6$ thereafter, with the same motivation\n",
    "as that of the schedule used in the previous examples.\n",
    "\n",
    "### Querying\n",
    "\n",
    "During training, to illustrate querying in LTN, we query over time two formulas which are not present in the knowledge base:\n",
    "- $\\phi_1 : \\forall p \\text { } C(p) \\implies S(p)$: states that who has cancer is also a smoker;\n",
    "- $\\phi_2 : \\forall p,q \\text{ } (C(p) \\lor C(q)) \\implies F(p,q)$: states that if at least one of two individuals in a pair\n",
    "have cancer then they are also friends.\n",
    "\n",
    "We use $p=5$ when approximating $\\forall$ since the impact of an outlier at querying time should be seen as more\n",
    "important than at learning time.\n",
    "\n",
    "In the following, we define also the two functions which compute $\\phi_1$ and $\\phi_2$ during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0 | loss 0.4282 | Train Sat 0.572 | Phi1 Sat 0.731 | Phi2 Sat 0.605\n",
      " epoch 20 | loss 0.4241 | Train Sat 0.576 | Phi1 Sat 0.748 | Phi2 Sat 0.605\n",
      " epoch 40 | loss 0.4173 | Train Sat 0.583 | Phi1 Sat 0.747 | Phi2 Sat 0.603\n",
      " epoch 60 | loss 0.4041 | Train Sat 0.596 | Phi1 Sat 0.748 | Phi2 Sat 0.604\n",
      " epoch 80 | loss 0.3814 | Train Sat 0.619 | Phi1 Sat 0.764 | Phi2 Sat 0.613\n",
      " epoch 100 | loss 0.3530 | Train Sat 0.647 | Phi1 Sat 0.801 | Phi2 Sat 0.609\n",
      " epoch 120 | loss 0.3288 | Train Sat 0.671 | Phi1 Sat 0.836 | Phi2 Sat 0.591\n",
      " epoch 140 | loss 0.3134 | Train Sat 0.687 | Phi1 Sat 0.881 | Phi2 Sat 0.570\n",
      " epoch 160 | loss 0.3047 | Train Sat 0.695 | Phi1 Sat 0.910 | Phi2 Sat 0.552\n",
      " epoch 180 | loss 0.2979 | Train Sat 0.702 | Phi1 Sat 0.926 | Phi2 Sat 0.538\n",
      " epoch 200 | loss 0.2921 | Train Sat 0.708 | Phi1 Sat 0.936 | Phi2 Sat 0.527\n",
      " epoch 220 | loss 0.2670 | Train Sat 0.733 | Phi1 Sat 0.941 | Phi2 Sat 0.422\n",
      " epoch 240 | loss 0.2590 | Train Sat 0.741 | Phi1 Sat 0.944 | Phi2 Sat 0.390\n",
      " epoch 260 | loss 0.2531 | Train Sat 0.747 | Phi1 Sat 0.944 | Phi2 Sat 0.380\n",
      " epoch 280 | loss 0.2465 | Train Sat 0.753 | Phi1 Sat 0.942 | Phi2 Sat 0.381\n",
      " epoch 300 | loss 0.2384 | Train Sat 0.762 | Phi1 Sat 0.940 | Phi2 Sat 0.377\n",
      " epoch 320 | loss 0.2293 | Train Sat 0.771 | Phi1 Sat 0.938 | Phi2 Sat 0.359\n",
      " epoch 340 | loss 0.2203 | Train Sat 0.780 | Phi1 Sat 0.938 | Phi2 Sat 0.343\n",
      " epoch 360 | loss 0.2110 | Train Sat 0.789 | Phi1 Sat 0.939 | Phi2 Sat 0.325\n",
      " epoch 380 | loss 0.2033 | Train Sat 0.797 | Phi1 Sat 0.943 | Phi2 Sat 0.312\n",
      " epoch 400 | loss 0.1970 | Train Sat 0.803 | Phi1 Sat 0.948 | Phi2 Sat 0.303\n",
      " epoch 420 | loss 0.1919 | Train Sat 0.808 | Phi1 Sat 0.947 | Phi2 Sat 0.296\n",
      " epoch 440 | loss 0.1886 | Train Sat 0.811 | Phi1 Sat 0.942 | Phi2 Sat 0.292\n",
      " epoch 460 | loss 0.1853 | Train Sat 0.815 | Phi1 Sat 0.940 | Phi2 Sat 0.288\n",
      " epoch 480 | loss 0.1822 | Train Sat 0.818 | Phi1 Sat 0.939 | Phi2 Sat 0.282\n",
      " epoch 500 | loss 0.1792 | Train Sat 0.821 | Phi1 Sat 0.939 | Phi2 Sat 0.276\n",
      " epoch 520 | loss 0.1754 | Train Sat 0.825 | Phi1 Sat 0.940 | Phi2 Sat 0.268\n",
      " epoch 540 | loss 0.1719 | Train Sat 0.828 | Phi1 Sat 0.940 | Phi2 Sat 0.259\n",
      " epoch 560 | loss 0.1694 | Train Sat 0.831 | Phi1 Sat 0.940 | Phi2 Sat 0.252\n",
      " epoch 580 | loss 0.1677 | Train Sat 0.832 | Phi1 Sat 0.940 | Phi2 Sat 0.247\n",
      " epoch 600 | loss 0.1666 | Train Sat 0.833 | Phi1 Sat 0.941 | Phi2 Sat 0.244\n",
      " epoch 620 | loss 0.1659 | Train Sat 0.834 | Phi1 Sat 0.941 | Phi2 Sat 0.241\n",
      " epoch 640 | loss 0.1654 | Train Sat 0.835 | Phi1 Sat 0.941 | Phi2 Sat 0.239\n",
      " epoch 660 | loss 0.1648 | Train Sat 0.835 | Phi1 Sat 0.941 | Phi2 Sat 0.236\n",
      " epoch 680 | loss 0.1615 | Train Sat 0.838 | Phi1 Sat 0.941 | Phi2 Sat 0.230\n",
      " epoch 700 | loss 0.1603 | Train Sat 0.840 | Phi1 Sat 0.941 | Phi2 Sat 0.227\n",
      " epoch 720 | loss 0.1560 | Train Sat 0.844 | Phi1 Sat 0.940 | Phi2 Sat 0.226\n",
      " epoch 740 | loss 0.1552 | Train Sat 0.845 | Phi1 Sat 0.940 | Phi2 Sat 0.224\n",
      " epoch 760 | loss 0.1547 | Train Sat 0.845 | Phi1 Sat 0.940 | Phi2 Sat 0.224\n",
      " epoch 780 | loss 0.1545 | Train Sat 0.846 | Phi1 Sat 0.940 | Phi2 Sat 0.223\n",
      " epoch 800 | loss 0.1543 | Train Sat 0.846 | Phi1 Sat 0.940 | Phi2 Sat 0.222\n",
      " epoch 820 | loss 0.1542 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.222\n",
      " epoch 840 | loss 0.1540 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.221\n",
      " epoch 860 | loss 0.1540 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.221\n",
      " epoch 880 | loss 0.1539 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.220\n",
      " epoch 900 | loss 0.1538 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.220\n",
      " epoch 920 | loss 0.1538 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.219\n",
      " epoch 940 | loss 0.1537 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.219\n",
      " epoch 960 | loss 0.1537 | Train Sat 0.846 | Phi1 Sat 0.941 | Phi2 Sat 0.219\n",
      " epoch 980 | loss 0.1536 | Train Sat 0.846 | Phi1 Sat 0.942 | Phi2 Sat 0.218\n"
     ]
    }
   ],
   "source": [
    "# functions which compute phi1 and phi2\n",
    "# we need disjunction connective for phi2\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "# this function returns the satisfaction level of the logical formula phi 1\n",
    "def phi1():\n",
    "    p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "    return Forall(p, Implies(C(p), S(p)), p=5).value\n",
    "\n",
    "# this function returns the satisfaction level of the logical formula phi2\n",
    "def phi2():\n",
    "    p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "    q = ltn.Variable(\"q\", torch.stack([i.value for i in g.values()]))\n",
    "    return Forall([p, q], Implies(Or(C(p), C(q)), F(p, q)), p=5).value\n",
    "\n",
    "# we have to optimize the parameters of the three predicates and also of the embeddings\n",
    "params = list(S.parameters()) + list(F.parameters()) + list(C.parameters()) + [i.value for i in g.values()]\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    if epoch <= 200:\n",
    "        p_exists = 1\n",
    "    else:\n",
    "        p_exists = 6\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # ground the variables\n",
    "    \"\"\"\n",
    "    NOTE: we update the embeddings at each step\n",
    "        -> we should re-compute the variables.\n",
    "    \"\"\"\n",
    "    x_ = ltn.Variable(\"x\", torch.stack([i.value for i in g.values()]))\n",
    "    y_ = ltn.Variable(\"y\", torch.stack([i.value for i in g.values()]))\n",
    "\n",
    "    sat_agg = SatAgg(\n",
    "        # Friends: knowledge incomplete in that\n",
    "        #     Friend(x,y) with x<y may be known\n",
    "        #     but Friend(y,x) may not be known\n",
    "        SatAgg(*[F(g[x], g[y]) for (x, y) in friends]),\n",
    "        SatAgg(*[Not(F(g[x], g[y])) for x in g1 for y in g1 if (x, y) not in friends and x < y] +\n",
    "                [Not(F(g[x], g[y])) for x in g2 for y in g2 if (x, y) not in friends and x < y]),\n",
    "\n",
    "        # Smokes: knowledge complete\n",
    "        SatAgg(*[S(g[x]) for x in smokes]),\n",
    "        SatAgg(*[Not(S(g[x])) for x in g if x not in smokes]),\n",
    "\n",
    "        # Cancer: knowledge complete in g1 only\n",
    "        SatAgg(*[C(g[x]) for x in cancer]),\n",
    "        SatAgg(*[Not(C(g[x])) for x in g1 if x not in cancer]),\n",
    "\n",
    "        # friendship is anti-reflexive (note that p=5)\n",
    "        Forall(x_, Not(F(x_, x_)), p=5),\n",
    "\n",
    "        # friendship is symmetric (note that p=5)\n",
    "        Forall([x_, y_], Implies(F(x_, y_), F(y_, x_)), p=5),\n",
    "\n",
    "        # everyone has a friend\n",
    "        Forall(x_, Exists(y_, F(x_, y_), p=p_exists)),\n",
    "\n",
    "        # smoking propagates among friends\n",
    "        Forall([x_, y_], Implies(And(F(x_, y_), S(x_)), S(y_))),\n",
    "\n",
    "        # smoking causes cancer + not smoking causes not cancer\n",
    "        Forall(x_, Implies(S(x_), C(x_))),\n",
    "        Forall(x_, Implies(Not(S(x_)), Not(C(x_))))\n",
    "    )\n",
    "    loss = 1. - sat_agg\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # we print metrics every 20 epochs of training\n",
    "    if epoch % 20 == 0:\n",
    "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Phi1 Sat %.3f | Phi2 Sat %.3f\" % (epoch, loss,\n",
    "                    sat_agg, phi1(), phi2()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that in this example we do not have a data loader like in previous examples. In fact, variables $x$ and $y$ are\n",
    "grounded with all the individuals at the beginning of each training step (epoch in this case).\n",
    "In particular, it is necessary to ground the variables at each training step because the constants inside the variables\n",
    "are constantly changing due to embedding learning step by step. Grounding the variables allows to PyTorch to recreate\n",
    "the computational graph and perform gradient tracking correctly among epochs.\n",
    "\n",
    "Notice also the use of `SatAgg` multiple times during one epoch of training. `SatAgg` is just a formula aggregator and\n",
    "can be used every time we need to aggregate the results of some formulas. For example, the first formula in our knowledge\n",
    "base is $F(u,v)$ for $(u, v) \\in \\mathcal{F}$. This formula is a set of formulas. `SatAgg` is used to compute the final\n",
    "result, obtained aggregating the results of all the formulas in the set.\n",
    "\n",
    "### Discussion on results\n",
    "\n",
    "The following plot shows the facts (axioms for $S(x)$, $C(x)$, and $F(x,y)$) in the knowledge base before the training of LTN.\n",
    "\n",
    "Yellow means that the value of the axiom is 1 (true), while violet means that the value of the axiom is 0 (false).\n",
    "\n",
    "It is possible to observe that there are a lot of missing facts (depicted in white)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x216 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows=999\n",
    "pd.options.display.max_columns=999\n",
    "pd.set_option('display.width',1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "def plt_heatmap(df, vmin=None, vmax=None):\n",
    "    plt.pcolor(df, vmin=vmin, vmax=vmax)\n",
    "    plt.yticks(np.arange(0.5,len(df.index),1),df.index)\n",
    "    plt.xticks(np.arange(0.5,len(df.columns),1),df.columns)\n",
    "    plt.colorbar()\n",
    "\n",
    "pd.set_option('precision',2)\n",
    "\n",
    "df_smokes_cancer_facts = pd.DataFrame(\n",
    "        np.array([[(x in smokes), (x in cancer) if x in g1 else math.nan] for x in g]),\n",
    "        columns=[\"S(x)\",\"C(x)\"],\n",
    "        index=list('abcdefghijklmn'))\n",
    "df_friends_ah_facts = pd.DataFrame(\n",
    "        np.array([[((x,y) in friends) if x<y else math.nan for x in g1] for y in g1]),\n",
    "        index = list('abcdefgh'),\n",
    "        columns = list('abcdefgh'))\n",
    "df_friends_in_facts = pd.DataFrame(\n",
    "        np.array([[((x,y) in friends) if x<y else math.nan for x in g2] for y in g2]),\n",
    "        index = list('ijklmn'),\n",
    "        columns = list('ijklmn'))\n",
    "\n",
    "p = ltn.Variable(\"p\", torch.stack([i.value for i in g.values()]))\n",
    "q = ltn.Variable(\"q\", torch.stack([i.value for i in g.values()]))\n",
    "\n",
    "df_smokes_cancer = pd.DataFrame(\n",
    "        torch.stack([S(p).value, C(p).value], dim=1).detach().numpy(),\n",
    "        columns=[\"S(x)\",\"C(x)\"],\n",
    "        index=list('abcdefghijklmn'))\n",
    "\n",
    "pred_friends = F(p, q).value\n",
    "df_friends_ah = pd.DataFrame(\n",
    "        pred_friends[:8,:8].detach().numpy(),\n",
    "        index=list('abcdefgh'),\n",
    "        columns=list('abcdefgh'))\n",
    "df_friends_in = pd.DataFrame(\n",
    "        pred_friends[8:,8:].detach().numpy(),\n",
    "        index=list('ijklmn'),\n",
    "        columns=list('ijklmn'))\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt_heatmap(df_smokes_cancer_facts, vmin=0, vmax=1)\n",
    "plt.subplot(132)\n",
    "plt.title(\"F(x,y) in Group 1\")\n",
    "plt_heatmap(df_friends_ah_facts, vmin=0, vmax=1)\n",
    "plt.subplot(133)\n",
    "plt.title(\"F(x,y) in Group 2\")\n",
    "plt_heatmap(df_friends_in_facts, vmin=0, vmax=1)\n",
    "#plt.savefig('ex_smokes_givenfacts.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we plot the truth values for $S(x), C(x), F(x,y)$, obtained by querying the predicates on all individuals by using\n",
    "LTN after it has been trained for 1000 epochs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x216 with 6 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt_heatmap(df_smokes_cancer, vmin=0, vmax=1)\n",
    "plt.subplot(132)\n",
    "plt.title(\"F(x,y) in Group 1\")\n",
    "plt_heatmap(df_friends_ah, vmin=0, vmax=1)\n",
    "plt.subplot(133)\n",
    "plt.title(\"F(x,y) in Group 2\")\n",
    "plt_heatmap(df_friends_in, vmin=0, vmax=1)\n",
    "#plt.savefig('ex_smokes_inferfacts.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to observe the following:\n",
    "- the friendship relations are learned as expected: $\\forall x \\text{ } (S(x) \\implies C(x))$ (smoke implies cancer) is\n",
    "inferred for group 2 even though such information was not present in the knowledge base;\n",
    "- for group 1, the given facts for smoking and cancer for the individuals $f$ and $g$ are slightly altered, as these\n",
    "were inconsistent with the rules. In fact, the rule for \"smoking propagating via friendship\" (\\forall x, y \\text{ } ((F(x, y) \\land S(x)) \\implies S(y))) is incompatible with\n",
    "many of the given facts. Increasing the satisfaction of this rule would require decreasing the overall satisfaction of\n",
    "the knowledge base, which explains why it is partly ignored by LTN during training.\n",
    "\n",
    "Finally, looking at the training logs, it can be seen that as the grounding approaches satisfiability of the knowledge base,\n",
    "$\\phi_1$ approaches true, whereas $\\phi_2$ approaches false, as expected."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}